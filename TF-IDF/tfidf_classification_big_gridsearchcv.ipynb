{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6W-1WTZoJCD",
        "outputId": "2fe2a260-fd44-4d60-abaa-93ce353a8fe3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bertopic in /usr/local/lib/python3.11/dist-packages (0.16.4)\n",
            "Requirement already satisfied: hdbscan>=0.8.29 in /usr/local/lib/python3.11/dist-packages (from bertopic) (0.8.40)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.11/dist-packages (from bertopic) (2.2.2)\n",
            "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (5.24.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib/python3.11/dist-packages (from bertopic) (1.6.1)\n",
            "Requirement already satisfied: sentence-transformers>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from bertopic) (3.4.1)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.11/dist-packages (from bertopic) (4.67.1)\n",
            "Requirement already satisfied: umap-learn>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (0.5.7)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan>=0.8.29->bertopic) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan>=0.8.29->bertopic) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2025.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=4.7.0->bertopic) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly>=4.7.0->bertopic) (24.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.5.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (4.48.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (2.5.1+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.28.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (11.1.0)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.0->bertopic) (0.61.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.0->bertopic) (0.5.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2024.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (4.12.2)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic) (0.44.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.5.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install bertopic\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler, RobustScaler, MaxAbsScaler\n",
        "from bertopic import BERTopic\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "t2k0lVUHoJCJ"
      },
      "outputs": [],
      "source": [
        "def encode_images(region_size, overlap, threshold, dataset, filter_common_values=False):\n",
        "\n",
        "    def pad_image(image, region_size, overlap):\n",
        "        \"\"\" Pads the image to ensure even division into regions \"\"\"\n",
        "        height, width = image.shape[1], image.shape[2]\n",
        "        stride = region_size - overlap\n",
        "        pad_height = (stride - (height % stride)) % stride\n",
        "        pad_width = (stride - (width % stride)) % stride\n",
        "\n",
        "        return F.pad(image, (0, pad_width, 0, pad_height), mode='constant', value=0)\n",
        "\n",
        "\n",
        "    def regions(image, size, overlap):\n",
        "        \"\"\" Extracts regions from the image \"\"\"\n",
        "        padded_image = pad_image(image, size, overlap)\n",
        "        regions = []\n",
        "        for i in range(0, padded_image.shape[1], size):\n",
        "            for j in range(0, padded_image.shape[2], size):\n",
        "                region = padded_image[0, i:i+size, j:j+size]\n",
        "                regions.append(region)\n",
        "\n",
        "        return regions\n",
        "\n",
        "\n",
        "    def encode(region, threshold):\n",
        "        \"\"\" Converts regions into binary encoded numbers \"\"\"\n",
        "        region = torch.where(region < threshold, 0, 1)\n",
        "        return int(''.join(map(str, region.flatten().int().tolist())), 2)\n",
        "\n",
        "    encoded_images = [[encode(region, threshold) for region in regions(image, region_size, overlap)]\n",
        "                      for image, _ in dataset]\n",
        "\n",
        "    if filter_common_values:\n",
        "        encoded_images = filter_frequent_values(encoded_images)\n",
        "\n",
        "    return [[x for x in img if x != 0] for img in encoded_images]  # Remove empty regions\n",
        "\n",
        "\n",
        "def filter_frequent_values(encoded_images):\n",
        "    \"\"\" Removes common pixel values across images to reduce redundancy \"\"\"\n",
        "    all_values = [val for img in encoded_images for val in img]\n",
        "    value_counts = pd.Series(all_values).value_counts()\n",
        "\n",
        "    # Define threshold for common values (e.g., if a value appears in more than 80% of images)\n",
        "    common_threshold = int(len(encoded_images) * 0.8)\n",
        "    common_values = set(value_counts[value_counts > common_threshold].index)\n",
        "\n",
        "    # Remove common values\n",
        "    filtered_images = [[val for val in img if val not in common_values] for img in encoded_images]\n",
        "    return filtered_images\n",
        "\n",
        "\n",
        "def create_groupeddf(encoded_images, dataset):\n",
        "    \"\"\" Converts encoded images into a grouped document dataframe \"\"\"\n",
        "    text_data = [' '.join(map(str, img)) for img in encoded_images]\n",
        "    df = pd.DataFrame({'Document': text_data, 'Label': dataset.targets.tolist()})\n",
        "\n",
        "    return df.groupby('Label', as_index=False).agg({'Document': ' '.join})\n",
        "\n",
        "\n",
        "def extract_ctfidf_features(groupeddf, score_threshold, scaling_factor, idf_weighting):\n",
        "    \"\"\" Computes cTF-IDF features with adjustable scaling and weighting \"\"\"\n",
        "    ctfidf, features = BERTopic()._c_tf_idf(groupeddf, fit=True)\n",
        "    ctfidf_array = ctfidf.toarray()\n",
        "\n",
        "    if idf_weighting == \"log\":\n",
        "        ctfidf_array = np.log1p(ctfidf_array)\n",
        "\n",
        "    ctfidf_features = {}\n",
        "    for idx, topic in enumerate(groupeddf['Label']):\n",
        "        top_indices = [i for i in range(len(features)) if ctfidf_array[idx][i] >= score_threshold]\n",
        "        scaled_features = []\n",
        "        for i in top_indices:\n",
        "            term = features[i]\n",
        "            count = max(1, int(ctfidf_array[idx][i] * scaling_factor))\n",
        "            scaled_features.extend([term] * count)\n",
        "        ctfidf_features[topic] = scaled_features\n",
        "\n",
        "    return ctfidf_features\n",
        "\n",
        "\n",
        "def model_with_params(region_size, overlap, threshold, score_threshold, scaling_factor, remove_common_values,\n",
        "                      fit_prior, idf_weighting, alpha, train_dataset, test_dataset):\n",
        "    \"\"\" Trains & evaluates Naïve Bayes model with given parameters \"\"\"\n",
        "\n",
        "    encoded_train = encode_images(region_size, overlap, threshold, train_dataset, filter_common_values=remove_common_values)\n",
        "    groupeddf = create_groupeddf(encoded_train, train_dataset)\n",
        "    ctfidf_features = extract_ctfidf_features(groupeddf, score_threshold, scaling_factor, idf_weighting)\n",
        "\n",
        "    X_train = [' '.join(words) for words in ctfidf_features.values()]\n",
        "    y_train = list(ctfidf_features.keys())\n",
        "\n",
        "    # Encode Testing Data\n",
        "    X_test = [' '.join(map(str, img)) for img in encode_images(region_size, overlap, threshold, test_dataset, filter_common_values=remove_common_values)]\n",
        "    y_test = test_dataset.targets.tolist()\n",
        "\n",
        "    # Vectorization\n",
        "    vectorizer = CountVectorizer()\n",
        "    X_train_vectors = vectorizer.fit_transform(X_train)\n",
        "    X_test_vectors = vectorizer.transform(X_test)\n",
        "\n",
        "    # Naïve Bayes Training\n",
        "    model = MultinomialNB(alpha=alpha, fit_prior=fit_prior)\n",
        "    model.fit(X_train_vectors, y_train)\n",
        "    y_pred = model.predict(X_test_vectors)\n",
        "\n",
        "    return accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "def measure_data_reduction_per_image(original_dataset, encoded_images, region_size, overlap):\n",
        "    \"\"\" Computes per-image data reduction and reports original vs encoded size \"\"\"\n",
        "\n",
        "    original_width, original_height = 28, 28\n",
        "    original_size = original_width * original_height  # 28 * 28 = 784 pixels\n",
        "\n",
        "    # Encoded size: derived from the number of non-zero regions per image\n",
        "    encoded_sizes = [len(img) for img in encoded_images]\n",
        "\n",
        "    # All images should have the same encoded size per test run\n",
        "    avg_encoded_size = np.mean(encoded_sizes)  # Get average encoded size (usually same for all)\n",
        "    encoded_width = encoded_height = int(np.sqrt(avg_encoded_size)) if avg_encoded_size > 0 else 0\n",
        "\n",
        "    # Calculate percentage reduction\n",
        "    reduction_percent = 100 * (1 - avg_encoded_size / original_size)\n",
        "\n",
        "    # Output information\n",
        "    print(f\"Original Image Size: {original_width}x{original_height} ({original_size} pixels)\")\n",
        "    print(f\"Encoded Image Size: ~{encoded_width}x{encoded_height} (~{int(avg_encoded_size)} pixels)\")\n",
        "    print(f\"Data Reduction Per Image: {reduction_percent:.2f}%\\n\")\n",
        "\n",
        "    return avg_encoded_size, reduction_percent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR3TNAyT0Qun",
        "outputId": "ffa4ad07-62f6-4b9a-a508-6c4a158d4621"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing Hyperparameter Combinations:\n",
            "\n",
            "**Testing:** region_size=6, overlap=1, threshold=-0.95, score_threshold=0.00015, scaling_factor=5000, remove_common_values=True, fit_prior=True, idf_weighting=log, alpha=1.5...\n",
            "Original Image Size: 28x28 (784 pixels)\n",
            "Encoded Image Size: ~4x4 (~18 pixels)\n",
            "Data Reduction Per Image: 97.61%\n",
            "\n",
            "**Accuracy:** 0.7200 | **Avg Data Reduction Per Image:** 18.71% | **Time:** 222.20 sec\n",
            "\n",
            "**Testing:** region_size=6, overlap=1, threshold=-0.95, score_threshold=0.00015, scaling_factor=5000, remove_common_values=True, fit_prior=True, idf_weighting=linear, alpha=1.5...\n",
            "Original Image Size: 28x28 (784 pixels)\n",
            "Encoded Image Size: ~4x4 (~18 pixels)\n",
            "Data Reduction Per Image: 97.61%\n",
            "\n",
            "**Accuracy:** 0.7197 | **Avg Data Reduction Per Image:** 18.71% | **Time:** 222.76 sec\n",
            "\n",
            "**Testing:** region_size=6, overlap=1, threshold=-0.95, score_threshold=0.00015, scaling_factor=5000, remove_common_values=True, fit_prior=False, idf_weighting=log, alpha=1.5...\n",
            "Original Image Size: 28x28 (784 pixels)\n",
            "Encoded Image Size: ~4x4 (~18 pixels)\n",
            "Data Reduction Per Image: 97.61%\n",
            "\n",
            "**Accuracy:** 0.7200 | **Avg Data Reduction Per Image:** 18.71% | **Time:** 218.34 sec\n",
            "\n",
            "**Testing:** region_size=6, overlap=1, threshold=-0.95, score_threshold=0.00015, scaling_factor=5000, remove_common_values=True, fit_prior=False, idf_weighting=linear, alpha=1.5...\n",
            "Original Image Size: 28x28 (784 pixels)\n",
            "Encoded Image Size: ~4x4 (~18 pixels)\n",
            "Data Reduction Per Image: 97.61%\n",
            "\n",
            "**Accuracy:** 0.7197 | **Avg Data Reduction Per Image:** 18.71% | **Time:** 219.75 sec\n",
            "\n",
            "**Testing:** region_size=6, overlap=1, threshold=-0.95, score_threshold=0.00015, scaling_factor=5000, remove_common_values=False, fit_prior=True, idf_weighting=log, alpha=1.5...\n",
            "Original Image Size: 28x28 (784 pixels)\n",
            "Encoded Image Size: ~4x4 (~18 pixels)\n",
            "Data Reduction Per Image: 97.61%\n",
            "\n",
            "**Accuracy:** 0.6591 | **Avg Data Reduction Per Image:** 18.71% | **Time:** 216.89 sec\n",
            "\n",
            "**Testing:** region_size=6, overlap=1, threshold=-0.95, score_threshold=0.00015, scaling_factor=5000, remove_common_values=False, fit_prior=True, idf_weighting=linear, alpha=1.5...\n",
            "Original Image Size: 28x28 (784 pixels)\n",
            "Encoded Image Size: ~4x4 (~18 pixels)\n",
            "Data Reduction Per Image: 97.61%\n",
            "\n",
            "**Accuracy:** 0.6549 | **Avg Data Reduction Per Image:** 18.71% | **Time:** 218.58 sec\n",
            "\n",
            "**Testing:** region_size=6, overlap=1, threshold=-0.95, score_threshold=0.00015, scaling_factor=5000, remove_common_values=False, fit_prior=False, idf_weighting=log, alpha=1.5...\n",
            "Original Image Size: 28x28 (784 pixels)\n",
            "Encoded Image Size: ~4x4 (~18 pixels)\n",
            "Data Reduction Per Image: 97.61%\n",
            "\n",
            "**Accuracy:** 0.6591 | **Avg Data Reduction Per Image:** 18.71% | **Time:** 215.67 sec\n",
            "\n",
            "**Testing:** region_size=6, overlap=1, threshold=-0.95, score_threshold=0.00015, scaling_factor=5000, remove_common_values=False, fit_prior=False, idf_weighting=linear, alpha=1.5...\n",
            "Original Image Size: 28x28 (784 pixels)\n",
            "Encoded Image Size: ~4x4 (~18 pixels)\n",
            "Data Reduction Per Image: 97.61%\n",
            "\n",
            "**Accuracy:** 0.6549 | **Avg Data Reduction Per Image:** 18.71% | **Time:** 216.25 sec\n",
            "\n",
            "**Testing:** region_size=6, overlap=1, threshold=-0.95, score_threshold=0.00015, scaling_factor=10000, remove_common_values=True, fit_prior=True, idf_weighting=log, alpha=1.5...\n",
            "Original Image Size: 28x28 (784 pixels)\n",
            "Encoded Image Size: ~4x4 (~18 pixels)\n",
            "Data Reduction Per Image: 97.61%\n",
            "\n",
            "**Accuracy:** 0.7421 | **Avg Data Reduction Per Image:** 18.71% | **Time:** 216.79 sec\n",
            "\n",
            "**Testing:** region_size=6, overlap=1, threshold=-0.95, score_threshold=0.00015, scaling_factor=10000, remove_common_values=True, fit_prior=True, idf_weighting=linear, alpha=1.5...\n",
            "Original Image Size: 28x28 (784 pixels)\n",
            "Encoded Image Size: ~4x4 (~18 pixels)\n",
            "Data Reduction Per Image: 97.61%\n",
            "\n",
            "**Accuracy:** 0.7421 | **Avg Data Reduction Per Image:** 18.71% | **Time:** 217.97 sec\n",
            "\n",
            "**Testing:** region_size=6, overlap=1, threshold=-0.95, score_threshold=0.00015, scaling_factor=10000, remove_common_values=True, fit_prior=False, idf_weighting=log, alpha=1.5...\n",
            "Original Image Size: 28x28 (784 pixels)\n",
            "Encoded Image Size: ~4x4 (~18 pixels)\n",
            "Data Reduction Per Image: 97.61%\n",
            "\n",
            "**Accuracy:** 0.7421 | **Avg Data Reduction Per Image:** 18.71% | **Time:** 218.17 sec\n",
            "\n",
            "**Testing:** region_size=6, overlap=1, threshold=-0.95, score_threshold=0.00015, scaling_factor=10000, remove_common_values=True, fit_prior=False, idf_weighting=linear, alpha=1.5...\n"
          ]
        }
      ],
      "source": [
        "def grid_search(train_dataset, test_dataset):\n",
        "    \"\"\" Runs grid search with specified hyperparameter combinations \"\"\"\n",
        "\n",
        "    param_grid = {\n",
        "        'region_size': [5, 6, 7],\n",
        "        'overlap': [1, 2, 3],\n",
        "        'threshold': [-0.95],\n",
        "        'score_threshold': [0.00015, 0.0002, 0.00025],\n",
        "        'scaling_factor': [5000, 10000, 15000],\n",
        "        'remove_common_values': [True, False],\n",
        "        'fit_prior': [True, False],\n",
        "        'idf_weighting': [\"log\", \"linear\"],\n",
        "        'alpha': [1.5]\n",
        "    }\n",
        "\n",
        "    results = []\n",
        "    print(\"Testing Hyperparameter Combinations:\\n\")\n",
        "\n",
        "    for region_size in param_grid['region_size']:\n",
        "        for overlap in param_grid['overlap']:\n",
        "            for threshold in param_grid['threshold']:\n",
        "                for score_threshold in param_grid['score_threshold']:\n",
        "                    for scaling_factor in param_grid['scaling_factor']:\n",
        "                        for remove_common_values in param_grid['remove_common_values']:\n",
        "                            for fit_prior in param_grid['fit_prior']:\n",
        "                                for idf_weighting in param_grid['idf_weighting']:\n",
        "                                    for alpha in param_grid['alpha']:\n",
        "\n",
        "                                        # Track start time\n",
        "                                        start_time = time.time()\n",
        "\n",
        "                                        print(f\"**Testing:** region_size={region_size}, overlap={overlap}, threshold={threshold}, score_threshold={score_threshold:.5f}, scaling_factor={scaling_factor}, remove_common_values={remove_common_values}, fit_prior={fit_prior}, idf_weighting={idf_weighting}, alpha={alpha}...\")\n",
        "\n",
        "                                        encoded_train = encode_images(region_size, overlap, threshold, train_dataset)\n",
        "                                        encoded_test = encode_images(region_size, overlap, threshold, test_dataset)\n",
        "\n",
        "                                        # Measure and report data reduction\n",
        "                                        avg_encoded_size, reduction_percent = measure_data_reduction_per_image(train_dataset, encoded_train, region_size, overlap)\n",
        "\n",
        "                                        accuracy = model_with_params(\n",
        "                                            region_size=region_size,\n",
        "                                            overlap=overlap,\n",
        "                                            threshold=threshold,\n",
        "                                            score_threshold=score_threshold,\n",
        "                                            scaling_factor=scaling_factor,\n",
        "                                            remove_common_values=remove_common_values,\n",
        "                                            fit_prior=fit_prior,\n",
        "                                            idf_weighting=idf_weighting,\n",
        "                                            alpha=alpha,\n",
        "                                            train_dataset=train_dataset,\n",
        "                                            test_dataset=test_dataset\n",
        "                                        )\n",
        "\n",
        "                                        # End timer\n",
        "                                        elapsed_time = time.time() - start_time\n",
        "\n",
        "                                        results.append((region_size, overlap, threshold, score_threshold, scaling_factor, remove_common_values, fit_prior, idf_weighting, alpha, accuracy, avg_encoded_size, reduction_percent, elapsed_time))\n",
        "                                        print(f\"**Accuracy:** {accuracy:.4f} | **Avg Data Reduction Per Image:** {avg_encoded_size:.2f}% | **Time:** {elapsed_time:.2f} sec\\n\")\n",
        "\n",
        "    # Extract best parameters based on accuracy\n",
        "    best_params = max(results, key=lambda x: x[9])  # x[10] is the accuracy score\n",
        "    best_score = best_params[9]\n",
        "\n",
        "    # Print all tested results\n",
        "    print(\"\\n**Hyperparameter Testing Results:**\")\n",
        "    for res in results:\n",
        "        print(f\"region_size={res[0]}, overlap={res[1]}, threshold={res[2]}, score_threshold={res[3]:.5f}, scaling_factor={res[4]}, remove_common_values={res[5]}, fit_prior={res[6]}, idf_weighting={res[7]}, alpha={res[8]} --> Accuracy: {res[9]:.4f} | Avg Encoded Size: {res[10]:.2f}% | Time: {res[12]:.2f} sec\")\n",
        "\n",
        "    # Print the best parameter combination\n",
        "    print(\"\\n**Best Parameters Found:**\")\n",
        "    print(f\"Region Size: {best_params[0]}, Overlap: {best_params[1]}, Threshold: {best_params[2]}, Score Threshold: {best_params[3]:.5f}, Scaling Factor: {best_params[4]}, Remove Common Values: {best_params[5]}, Fit Prior: {best_params[6]}, IDF Weighting: {best_params[7]}, Alpha: {best_params[8]}\")\n",
        "    print(f\"Best Accuracy: {best_score:.4f} | Avg Encoded Size: {best_params[10]:.2f}%\")\n",
        "\n",
        "    return best_params\n",
        "\n",
        "# Run optimized grid search\n",
        "best_params = grid_search(train_dataset, test_dataset)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
