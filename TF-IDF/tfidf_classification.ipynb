{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic import BERTopic\n",
    "\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([ #normalized data, can be done without normalized data but threshold will need to be changed\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regions(image, size): #divide image into non overlapping regions of specified size\n",
    "    image.numpy()\n",
    "    regions = []\n",
    "    for i in range(0, 28, size): \n",
    "        for j in range(0, 28, size):\n",
    "            region = image[0, i:i+size, j:j+size]\n",
    "            regions.append(region)\n",
    "    return regions\n",
    "\n",
    "def encode(region, threshold): # Currently very inefficient, need to get rid of for loops but works for now\n",
    "    for i in range(len(region)):\n",
    "        for j in range(len(region[0])):\n",
    "            region[i][j] = 0 if region[i][j]< threshold else 1\n",
    "    binary = ''.join(map(str, region.numpy().flatten().astype(int).tolist())) #bunch of mumbo jumbo to 'unfold' the region and turn it into one binary string\n",
    "    value = int(binary, 2) #convert binary to decimal\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_size = 7 # for 4x4 region max binary value is 65535\n",
    "threshold = -0.5\n",
    "\n",
    "encoded_images = []\n",
    "for image, label in train_dataset: #with the for loops, took my laptop around 30 min to run on 4x4\n",
    "    r = regions(image, region_size)\n",
    "    for i in range(len(r)):\n",
    "        r[i] = encode(r[i], threshold)\n",
    "    encoded_images.append(r) #in theory this encodes all the regions and stores them. each image is its own list of decimal regions\n",
    "    \n",
    "for i in range(len(encoded_images)):\n",
    "    encoded_images[i] = [x for x in encoded_images[i] if x != 0] #remove any regions that are just 0 (all black/no important features according to threshold)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "2 129 8256 26596060923662 4433217897375 283691179835392 62089926279168 35182224605184 557662341367310 62057474949120\n"
     ]
    }
   ],
   "source": [
    "text_data = [' '.join(map(str,encoded_images[i])) for i in range(len(encoded_images))]\n",
    "print(len(text_data))\n",
    "print(text_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LENGTH:  60000\n",
      "LENGTH:  10\n"
     ]
    }
   ],
   "source": [
    "text_data = [' '.join(map(str,encoded_images[i])) for i in range(len(encoded_images))] #joins the regions together into one string instead of a list of strings\n",
    "\n",
    "traindata = {'Document':text_data, 'Label':train_dataset.targets.tolist()} #dataframe of images and labels\n",
    "traindf = pd.DataFrame(traindata)\n",
    "print('LENGTH: ', len(traindf))\n",
    "\n",
    "groupeddf = traindf.groupby('Label', as_index=False).agg({'Document': ''.join}) #dataframe of documents grouped by class (all documents of one class are combined into a mega document)\n",
    "print('LENGTH: ', len(groupeddf))\n",
    "nums = groupeddf['Document']\n",
    "labels = groupeddf['Label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>466814 4640475700784 562948714020993 283691315...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>911 1 67009669708912 13299112724382 4255283140...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1662 13717922250753 557677373785982 16771 1372...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>143 16383 64 137404593733647 562917504712702 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2 129 8256 26596060923662 4433217897375 283691...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                           Document\n",
       "0      0  466814 4640475700784 562948714020993 283691315...\n",
       "1      1  911 1 67009669708912 13299112724382 4255283140...\n",
       "2      2  1662 13717922250753 557677373785982 16771 1372...\n",
       "3      3  143 16383 64 137404593733647 562917504712702 2...\n",
       "4      4  2 129 8256 26596060923662 4433217897375 283691..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupeddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words for Class 0:\n",
      "['4398046511104', '64', '13228499271680', '562932505116672', '129', '562949684985856', '4432406249472', '13298030395777', '283673999966208', '562949416550400']\n",
      "Top words for Class 1:\n",
      "['4432676798593', '425536972664928', '129', '496459801442416', '13298030395779', '4432674684928', '13298024054784', '425528314036224', '16513', '4432406249472']\n",
      "Top words for Class 2:\n",
      "['4398046511104', '64', '13194139533312', '4432406249472', '13228499271680', '562915593682944', '8256', '8288', '30786325577728', '558551906910208']\n",
      "Top words for Class 3:\n",
      "['64', '16383', '4398046511104', '562949684985856', '4432406249472', '13228499271680', '15484', '96', '12400', '8288']\n",
      "Top words for Class 4:\n",
      "['281474976710656', '64', '4432674684928', '8256', '283673999966208', '4432676782080', '4432406249472', '12384', '129', '13298030346240']\n",
      "Top words for Class 5:\n",
      "['4398046511104', '16383', '422212465065984', '127', '4432406249472', '64', '281474976710656', '129', '492581209243648', '16513']\n",
      "Top words for Class 6:\n",
      "['30786325577728', '65970697666560', '13194139533312', '136339441844224', '64', '66211215835136', '4398046511104', '30889404792832', '136854837919744', '277076930199552']\n",
      "Top words for Class 7:\n",
      "['129', '16515', '281474976710656', '16775', '131', '96', '64', '2113923', '112', '283673999966208']\n",
      "Top words for Class 8:\n",
      "['64', '16383', '16255', '15484', '15998', '8288', '14456', '8256', '4432406249472', '4432674684928']\n",
      "Top words for Class 9:\n",
      "['112', '120', '96', '124', '64', '4432406249472', '4398046511104', '126', '4432676798464', '281474976710656']\n"
     ]
    }
   ],
   "source": [
    "#cvectorizer = CountVectorizer()\n",
    "#count = cvectorizer.fit_transform(features)\n",
    "#nums = cvectorizer.get_feature_names_out()\n",
    "\n",
    "ctfidf, features = BERTopic()._c_tf_idf(groupeddf, fit=True) #class based TFIDF\n",
    "ctfidf_array = ctfidf.toarray()\n",
    "\n",
    "for idx, topic in enumerate(groupeddf['Label']): #print the top 10 words for each class\n",
    "    print(f\"Top words for Class {topic}:\")\n",
    "    top_indices = ctfidf_array[idx].argsort()[-10:][::-1]\n",
    "    top_words = [features[i] for i in top_indices]\n",
    "    print(top_words)\n",
    "    \n",
    "#For whatever reason it pulls in the same number as the highest rated number for all classes\n",
    "#Can we just scrap those or is it a broader issue and are the rest of the numbers wrong?\n",
    "#Same thing happened when the model was broken and was only 1s, it had all 1s preceded by the class number\n",
    "#Here it is all 0s preceded by the class number\n",
    "#also maybe need to go even bigger on the region based on the fact that the highest rated number for 3 classes is a white brick of all 1s\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THOUGHTS?\n",
    "Optimize encoding  \n",
    "Create dictionary of top 10 or so words per class  \n",
    "Use that as the training data in the naive bayes classifier  \n",
    "Encode the testing data, remove all 0s  \n",
    "Remove more data?\n",
    "Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer() #individual document tfidf instead of class based tfidf\n",
    "tfidf_matrix = vectorizer.fit_transform(text_data)\n",
    "\n",
    "tfidf_array = tfidf_matrix.toarray()\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "\n",
    "filtered_images = []\n",
    "for i, image in enumerate(encoded_images):\n",
    "    filtered_image = [\n",
    "        int(feature_names[j])  # Convert feature name (string) back to integer\n",
    "        for j in range(len(feature_names))\n",
    "        if tfidf_array[i, j] >= 0.5  # Keep only values with TF-IDF >= 0.5\n",
    "    ]\n",
    "    filtered_images.append(filtered_image)\n",
    "\n",
    "train_dataset = [filtered_images, train_dataset[:][[1]]]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
